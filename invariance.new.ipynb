{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import ot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvarianceNNGraph(Model, layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(InvarianceNNGraph, self).__init__()\n",
    "        self.weight = {'weight1': self.add_weight(shape=(64, 32), initializer='random_normal', trainable=True), \n",
    "                        'weight2': self.add_weight(shape=(32, 16), initializer='random_normal', trainable=True), \n",
    "                        'weight3': self.add_weight(shape=(16, 6), initializer='random_normal', trainable=True),\n",
    "                        'weight_final': self.add_weight(shape = (6,1), initializer = 'random_normal', trainable = True)}\n",
    "        self.bias = {'bias1': self.add_weight(shape=(32, ), initializer='random_normal', trainable=True), \n",
    "                        'bias2': self.add_weight(shape=(16, ), initializer='random_normal', trainable=True), \n",
    "                        'bias3': self.add_weight(shape=(6, ), initializer='random_normal', trainable=True),\n",
    "                        'bias_final0': self.add_weight(shape = (1,), initializer = 'random_normal', trainable = True), \n",
    "                        'bias_final1': self.add_weight(shape = (1,), initializer = 'random_normal', trainable = True)}\n",
    "        \n",
    "    def invariantMap(self, x):\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weight['weight1']), self.bias['bias1']))\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(out, self.weight['weight2']), self.bias['bias2']))\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(out, self.weight['weight3']), self.bias['bias3']))\n",
    "        return out\n",
    "        \n",
    "    def call(self, x, env = 0, is_training = False):\n",
    "        if env == 0:\n",
    "            out = tf.add(tf.matmul(self.invariantMap(x), self.weight['weight_final']) , self.bias['bias_final0'])\n",
    "            out = tf.concat([-out, out], axis = 1)\n",
    "            #predict_prob = tf.nn.sigmoid(tf.add(tf.matmul(self.invariantMap(x), self.weight['weight_final']), self.bias['bias_final0']))\n",
    "            #predict_prob2 = tf.concat([1- predict_prob, predict_prob], axis = 1)\n",
    "            if is_training:\n",
    "                return out#tf.argmax(predict_prob2, axis = 1)\n",
    "            else: \n",
    "                return tf.nn.softmax(out)\n",
    "            \n",
    "        elif env == 1:\n",
    "            out = tf.add(tf.matmul(self.invariantMap(x), self.weight['weight_final']), self.bias['bias_final1'])\n",
    "            out = tf.concat([-out, out], axis = 1)\n",
    "            #predict_prob = tf.nn.sigmoid(tf.add(tf.matmul(self.invariantMap(x), self.weight['weight_final']), self.bias['bias_final1']))\n",
    "            #predict_prob2 = tf.concat([1- predict_prob, predict_prob], axis = 1)\n",
    "            if is_training:\n",
    "                return out #tf.argmax(predict_prob2, axis = 1)\n",
    "            else: \n",
    "                return tf.nn.softmax(out) #predict_prob\n",
    "inv = InvarianceNNGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=133, shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-0.6171767 , -0.77536714],\n",
       "       [-0.6172655 , -0.7752631 ],\n",
       "       [-0.6171934 , -0.7753476 ],\n",
       "       [-0.617163  , -0.7753833 ],\n",
       "       [-0.617281  , -0.7752451 ],\n",
       "       [-0.6173059 , -0.77521574],\n",
       "       [-0.6172641 , -0.7752648 ],\n",
       "       [-0.61726373, -0.7752652 ],\n",
       "       [-0.617303  , -0.7752194 ],\n",
       "       [-0.61719525, -0.77534527]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.normal(0, 1, (10, 64))\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "u = inv(x, is_training = False)\n",
    "tf.math.log(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmat(x, y):\n",
    "    \"\"\"\n",
    "    :param x: (na, 2)\n",
    "    :param y: (nb, 2)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mmp1 = tf.tile(tf.expand_dims(x, axis=1), [1, y.shape[0], 1])  # (na, nb, 2)\n",
    "    mmp2 = tf.tile(tf.expand_dims(y, axis=0), [x.shape[0], 1, 1])  # (na, nb, 2)\n",
    "\n",
    "    mm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(mmp1, mmp2)), axis=2))  # (na, nb)\n",
    "    mm = tf.cast(mm, dtype = tf.float32)\n",
    "    return mm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def WDist(x, y, wReg):\n",
    "    nx = x.shape[0]\n",
    "    ny = y.shape[0]\n",
    "    M = dmat(x,y)\n",
    "    M = np.array(M)\n",
    "    histX = np.ones((nx,))/nx\n",
    "    histY = np.ones((ny,))/ny\n",
    "    T = ot.sinkhorn(histX, histY, M, wReg)\n",
    "    T = tf.cast(T, dtype = tf.float32)\n",
    "    return tf.reduce_sum(tf.math.multiply(M, T))\n",
    "\n",
    "\n",
    "def WDistLoss(modifiedDict, reg):\n",
    "    loss = tf.cast([WDist(inv.invariantMap(modifiedDict[0][x]), inv.invariantMap(modifiedDict[1][x]), reg) \n",
    "                            for x in range(2)], dtype=tf.float32)\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "def cross_entropy_loss(y, predict_prob):\n",
    "    y = tf.one_hot(y, 2)\n",
    "    loss = -y*tf.math.log(predict_prob)\n",
    "    return 2*tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def makeModifiedDict(dataDict):\n",
    "    retDict = dict()\n",
    "    for key in dataDict:\n",
    "        retDict[key] = dict()\n",
    "        dHand = retDict[key]\n",
    "        x = dataDict[key]['x']\n",
    "        y = dataDict[key]['y']\n",
    "        dHand[0] = tf.cast(x[y == 0], dtype=tf.float32)\n",
    "        dHand[1] = tf.cast(x[y == 1], dtype=tf.float32)\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.cast(np.random.normal(0, 1, (100, 64)), dtype = tf.float32)\n",
    "x1 = tf.cast(np.random.normal(1, 1, (150, 64)), dtype=tf.float32)\n",
    "y0 = tf.cast(np.random.normal(0, 1, (100, 64)), dtype=tf.float32)\n",
    "y1 = tf.cast(np.random.normal(1, 1, (150, 64)), dtype=tf.float32)\n",
    "dataDict = dict()\n",
    "dataDict[0] = {0: x0, 1: x1}\n",
    "dataDict[1] = {0: y0, 1: y1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=242, shape=(), dtype=float32, numpy=0.0025236334>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WDistLoss(dataDict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=281, shape=(), dtype=float32, numpy=0.69570327>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0 = np.random.binomial(1, 0.5, (1200,))\n",
    "y1 = np.random.binomial(1, 0.8, (1500,))\n",
    "f = lambda y: np.random.normal(1, 1, (64,)) if y else np.random.normal(0, 1, (64,))\n",
    "x0 = [f(y) for y in y0]\n",
    "x1 = [f(y) for y in y1]\n",
    "#y0 = tf.one_hot(y0, 2)\n",
    "#y1 = tf.one_hot(y1, 2)\n",
    "x0 = tf.cast(x0, dtype= tf.float32)\n",
    "x1 = tf.cast(x1, dtype= tf.float32)\n",
    "dataDict = {0: {'x': x0, 'y': y0}, 1: {'x': x1, 'y': y1}}\n",
    "prob = inv(x0)\n",
    "c = cross_entropy_loss(y0, prob)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "num_steps = 100\n",
    "for key in dataDict:\n",
    "    dictHand = dataDict[key]\n",
    "    batch = tf.data.Dataset.from_tensor_slices((dictHand['x'], dictHand['y']))\n",
    "    batch = batch.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "    dictHand['batch'] = batch.take(num_steps)\n",
    "    \n",
    "learningRate = 0.01\n",
    "optimizer = tf.optimizers.Adam(learningRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunOptimizer(trainDataDict, lr, reg, lam):\n",
    "    with tf.GradientTape() as g:\n",
    "        modifiedDict = makeModifiedDict(trainDataDict)\n",
    "        loss = lam*WDistLoss(modifiedDict, reg)\n",
    "        for env in trainDataDict:\n",
    "            dictHand = trainDataDict[env]\n",
    "            predict_prob = inv(dictHand['x'])\n",
    "            loss += cross_entropy_loss(dictHand['y'], predict_prob)\n",
    "        \n",
    "    trainable_vars = inv.trainable_variables\n",
    "    gradients = g.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    trainDataDict = dataDict\n",
    "    modifiedDict = makeModifiedDict(trainDataDict)\n",
    "    loss = WDistLoss(modifiedDict, 0.5)\n",
    "    for env in trainDataDict:\n",
    "        dictHand = trainDataDict[env]\n",
    "        logits = inv(dictHand['x'])\n",
    "        loss += cross_entropy_loss(dictHand['y'], logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=731, shape=(64, 32), dtype=float32, numpy=\n",
       " array([[-6.2274839e-06, -2.4451609e-05,  2.7979222e-06, ...,\n",
       "          3.4066805e-05, -3.4612449e-06,  1.7386556e-05],\n",
       "        [-6.2019135e-06, -2.3625422e-05,  2.7308733e-06, ...,\n",
       "          3.3042568e-05, -3.3285392e-06,  1.6836180e-05],\n",
       "        [-6.0096327e-06, -2.3207926e-05,  2.6405708e-06, ...,\n",
       "          3.1855998e-05, -3.3150689e-06,  1.6257571e-05],\n",
       "        ...,\n",
       "        [-6.3031794e-06, -2.4055231e-05,  2.7643487e-06, ...,\n",
       "          3.3723732e-05, -3.4139412e-06,  1.7041515e-05],\n",
       "        [-6.0333723e-06, -2.3516379e-05,  2.6968105e-06, ...,\n",
       "          3.2740034e-05, -3.3314404e-06,  1.6429136e-05],\n",
       "        [-6.2785493e-06, -2.4549736e-05,  2.8262405e-06, ...,\n",
       "          3.4050656e-05, -3.5094276e-06,  1.7581318e-05]], dtype=float32)>,\n",
       " <tf.Tensor: id=732, shape=(32, 16), dtype=float32, numpy=\n",
       " array([[-1.77804177e-04,  2.10071958e-04,  4.03544283e-04,\n",
       "         -3.02262924e-04, -1.09264520e-05,  8.84566689e-05,\n",
       "         -6.20645224e-05,  2.34307983e-04, -1.21891411e-04,\n",
       "         -2.18021174e-04, -3.18902778e-04, -2.56244966e-05,\n",
       "          8.64016474e-05, -9.60882680e-05,  2.57817621e-04,\n",
       "          5.19904461e-05],\n",
       "        [-1.16012590e-04,  1.37574854e-04,  2.64282193e-04,\n",
       "         -1.97811431e-04, -7.15360648e-06,  5.79045955e-05,\n",
       "         -4.06336294e-05,  1.53384462e-04, -7.98402980e-05,\n",
       "         -1.42844539e-04, -2.08693571e-04, -1.67736107e-05,\n",
       "          5.65758382e-05, -6.29043789e-05,  1.68682993e-04,\n",
       "          3.40381594e-05],\n",
       "        [-1.28418178e-04,  1.51976870e-04,  2.91984790e-04,\n",
       "         -2.18579386e-04, -7.90307786e-06,  6.39979626e-05,\n",
       "         -4.48979881e-05,  1.69488514e-04, -8.82046734e-05,\n",
       "         -1.57820585e-04, -2.30640522e-04, -1.85323224e-05,\n",
       "          6.25125103e-05, -6.95012131e-05,  1.86418911e-04,\n",
       "          3.76038624e-05],\n",
       "        [-1.22744677e-04,  1.45434591e-04,  2.79351545e-04,\n",
       "         -2.09115591e-04, -7.56194049e-06,  6.12140575e-05,\n",
       "         -4.29504253e-05,  1.62160315e-04, -8.43974485e-05,\n",
       "         -1.51005966e-04, -2.20614762e-04, -1.77305101e-05,\n",
       "          5.98074585e-05, -6.65016560e-05,  1.78367729e-04,\n",
       "          3.59812038e-05],\n",
       "        [-1.29249922e-04,  1.53008223e-04,  2.93893798e-04,\n",
       "         -2.20033529e-04, -7.95506821e-06,  6.44102038e-05,\n",
       "         -4.51891356e-05,  1.70601998e-04, -8.87759816e-05,\n",
       "         -1.58884228e-04, -2.32146849e-04, -1.86555517e-05,\n",
       "          6.29244896e-05, -6.99650336e-05,  1.87635742e-04,\n",
       "          3.78535224e-05],\n",
       "        [-1.97706366e-04,  2.33306579e-04,  4.48219187e-04,\n",
       "         -3.35742166e-04, -1.21364701e-05,  9.82571219e-05,\n",
       "         -6.89329099e-05,  2.60268454e-04, -1.35376933e-04,\n",
       "         -2.42175214e-04, -3.54265474e-04, -2.84657071e-05,\n",
       "          9.59692625e-05, -1.06731313e-04,  2.86444731e-04,\n",
       "          5.77462379e-05],\n",
       "        [-1.69167295e-04,  1.99762697e-04,  3.83764447e-04,\n",
       "         -2.87433446e-04, -1.03914354e-05,  8.41178189e-05,\n",
       "         -5.90212512e-05,  2.22821560e-04, -1.15911775e-04,\n",
       "         -2.07407720e-04, -3.03262757e-04, -2.43690829e-05,\n",
       "          8.21656868e-05, -9.13782278e-05,  2.45180592e-04,\n",
       "          4.94427950e-05],\n",
       "        [-3.98141856e-05,  4.80491653e-05,  9.22512409e-05,\n",
       "         -6.88289874e-05, -2.49425602e-06,  2.01765506e-05,\n",
       "         -1.41764949e-05,  5.34612773e-05, -2.79221385e-05,\n",
       "         -5.00074530e-05, -7.25546706e-05, -5.83614974e-06,\n",
       "          1.97407953e-05, -2.19301655e-05,  5.86128699e-05,\n",
       "          1.18684920e-05],\n",
       "        [-1.90403836e-04,  2.24624455e-04,  4.31564171e-04,\n",
       "         -3.23296030e-04, -1.16860783e-05,  9.46171640e-05,\n",
       "         -6.63782412e-05,  2.50623503e-04, -1.30341185e-04,\n",
       "         -2.33166473e-04, -3.41161998e-04, -2.74077101e-05,\n",
       "          9.24130727e-05, -1.02769351e-04,  2.75777187e-04,\n",
       "          5.56001760e-05],\n",
       "        [-1.06038286e-04,  1.25758117e-04,  2.41536778e-04,\n",
       "         -1.80795279e-04, -6.53832967e-06,  5.29288627e-05,\n",
       "         -3.71358983e-05,  1.40207834e-04, -7.29810054e-05,\n",
       "         -1.30597997e-04, -1.90694889e-04, -1.53287419e-05,\n",
       "          5.17146727e-05, -5.74996811e-05,  1.54190086e-04,\n",
       "          3.11101867e-05],\n",
       "        [-1.25568055e-04,  1.48670864e-04,  2.85555318e-04,\n",
       "         -2.13768421e-04, -7.72997646e-06,  6.25835964e-05,\n",
       "         -4.39067189e-05,  1.65770834e-04, -8.62545203e-05,\n",
       "         -1.54395544e-04, -2.25556054e-04, -1.81270752e-05,\n",
       "          6.11394571e-05, -6.79800796e-05,  1.82320800e-04,\n",
       "          3.67777029e-05],\n",
       "        [-8.34141974e-05,  9.92592104e-05,  1.90631559e-04,\n",
       "         -1.42622535e-04, -5.15879128e-06,  4.17505544e-05,\n",
       "         -2.93066641e-05,  1.10609573e-04, -5.75933664e-05,\n",
       "         -1.03090497e-04, -1.50442589e-04, -1.20927580e-05,\n",
       "          4.08065207e-05, -4.53676839e-05,  1.21570709e-04,\n",
       "          2.45500742e-05],\n",
       "        [-1.38355172e-04,  1.63605771e-04,  3.14296572e-04,\n",
       "         -2.35355372e-04, -8.50938795e-06,  6.89014705e-05,\n",
       "         -4.83341792e-05,  1.82494899e-04, -9.49640307e-05,\n",
       "         -1.69920793e-04, -2.48328754e-04, -1.99543774e-05,\n",
       "          6.73036993e-05, -7.48401435e-05,  2.00738607e-04,\n",
       "          4.04848179e-05],\n",
       "        [-1.62937096e-04,  1.92552456e-04,  3.69897985e-04,\n",
       "         -2.77083425e-04, -1.00162151e-05,  8.10861820e-05,\n",
       "         -5.68873584e-05,  2.14794884e-04, -1.11743546e-04,\n",
       "         -1.99887494e-04, -2.92321580e-04, -2.34888266e-05,\n",
       "          7.92072387e-05, -8.80857770e-05,  2.36342952e-04,\n",
       "          4.76561036e-05],\n",
       "        [-1.59353891e-04,  1.88324149e-04,  3.61791230e-04,\n",
       "         -2.70935940e-04, -9.79540710e-06,  7.93005456e-05,\n",
       "         -5.56346204e-05,  2.10038677e-04, -1.09267363e-04,\n",
       "         -1.95508532e-04, -2.85839807e-04, -2.29725592e-05,\n",
       "          7.74567889e-05, -8.61300941e-05,  2.31112470e-04,\n",
       "          4.66048841e-05],\n",
       "        [-1.14273265e-04,  1.35380411e-04,  2.60051165e-04,\n",
       "         -1.94671869e-04, -7.03909109e-06,  5.69934746e-05,\n",
       "         -3.99891178e-05,  1.50965803e-04, -7.85781667e-05,\n",
       "         -1.40619362e-04, -2.05389806e-04, -1.65033507e-05,\n",
       "          5.56816703e-05, -6.19152197e-05,  1.66005630e-04,\n",
       "          3.34949473e-05],\n",
       "        [-1.35797614e-04,  1.60601179e-04,  3.08544695e-04,\n",
       "         -2.31047175e-04, -8.35384344e-06,  6.76204800e-05,\n",
       "         -4.74508488e-05,  1.79133815e-04, -9.32007606e-05,\n",
       "         -1.66788479e-04, -2.43771399e-04, -1.95873054e-05,\n",
       "          6.60593651e-05, -7.34597561e-05,  1.97048983e-04,\n",
       "          3.97459007e-05],\n",
       "        [-7.85884258e-05,  9.34887576e-05,  1.79618844e-04,\n",
       "         -1.34348229e-04, -4.86136287e-06,  3.93420487e-05,\n",
       "         -2.76134851e-05,  1.04215913e-04, -5.42810558e-05,\n",
       "         -9.72098787e-05, -1.41716897e-04, -1.13929773e-05,\n",
       "          3.84486484e-05, -4.27367922e-05,  1.14504648e-04,\n",
       "          2.31201138e-05],\n",
       "        [-1.45059865e-04,  1.71513122e-04,  3.29438830e-04,\n",
       "         -2.46717449e-04, -8.91920899e-06,  7.22075274e-05,\n",
       "         -5.06701472e-05,  1.91262676e-04, -9.95176160e-05,\n",
       "         -1.78073402e-04, -2.60257133e-04, -2.09147456e-05,\n",
       "          7.05368147e-05, -7.84415752e-05,  2.10378159e-04,\n",
       "          4.24436475e-05],\n",
       "        [-1.07306114e-04,  1.27357722e-04,  2.44617753e-04,\n",
       "         -1.83081007e-04, -6.62056027e-06,  5.36017178e-05,\n",
       "         -3.76102435e-05,  1.41969111e-04, -7.38878662e-05,\n",
       "         -1.32267451e-04, -1.93130094e-04, -1.55216003e-05,\n",
       "          5.23689669e-05, -5.82198518e-05,  1.56073249e-04,\n",
       "          3.15057623e-05],\n",
       "        [-2.00503593e-04,  2.36614898e-04,  4.54573252e-04,\n",
       "         -3.40529194e-04, -1.23090203e-05,  9.96508461e-05,\n",
       "         -6.99081356e-05,  2.63966678e-04, -1.37298775e-04,\n",
       "         -2.45565752e-04, -3.59282305e-04, -2.88693664e-05,\n",
       "          9.73296774e-05, -1.08246626e-04,  2.90522090e-04,\n",
       "          5.85669040e-05],\n",
       "        [-1.43749770e-04,  1.70116968e-04,  3.26808426e-04,\n",
       "         -2.44671566e-04, -8.84665224e-06,  7.16253053e-05,\n",
       "         -5.02515577e-05,  1.89700368e-04, -9.86906161e-05,\n",
       "         -1.76652175e-04, -2.58166925e-04, -2.07463163e-05,\n",
       "          6.99628436e-05, -7.77894893e-05,  2.08684331e-04,\n",
       "          4.20946089e-05],\n",
       "        [-1.33238485e-04,  1.57744726e-04,  3.02988046e-04,\n",
       "         -2.26885677e-04, -8.20323476e-06,  6.64074687e-05,\n",
       "         -4.65898884e-05,  1.75894718e-04, -9.15229975e-05,\n",
       "         -1.63781107e-04, -2.39346613e-04, -1.92371936e-05,\n",
       "          6.48710993e-05, -7.21385368e-05,  1.93491200e-04,\n",
       "          3.90278256e-05],\n",
       "        [-2.07769961e-04,  2.45166710e-04,  4.70978033e-04,\n",
       "         -3.52852454e-04, -1.27533240e-05,  1.03248509e-04,\n",
       "         -7.24331621e-05,  2.73495039e-04, -1.42243269e-04,\n",
       "         -2.54430604e-04, -3.72303970e-04, -2.99139501e-05,\n",
       "          1.00844758e-04, -1.12159119e-04,  3.01011692e-04,\n",
       "          6.06814938e-05],\n",
       "        [-1.47322469e-04,  1.74182569e-04,  3.34618991e-04,\n",
       "         -2.50588026e-04, -9.05979414e-06,  7.33342458e-05,\n",
       "         -5.14538551e-05,  1.94270833e-04, -1.01076599e-04,\n",
       "         -1.80823292e-04, -2.64369242e-04, -2.12458235e-05,\n",
       "          7.16411014e-05, -7.96752793e-05,  2.13719439e-04,\n",
       "          4.31039080e-05],\n",
       "        [-1.72560642e-04,  2.03863601e-04,  3.91652546e-04,\n",
       "         -2.93337711e-04, -1.06042944e-05,  8.58488493e-05,\n",
       "         -6.02299842e-05,  2.27390512e-04, -1.18296943e-04,\n",
       "         -2.11589897e-04, -3.09478608e-04, -2.48697379e-05,\n",
       "          8.38538981e-05, -9.32509502e-05,  2.50220124e-04,\n",
       "          5.04556956e-05],\n",
       "        [-1.17666896e-04,  1.39421347e-04,  2.67792580e-04,\n",
       "         -2.00470371e-04, -7.24964048e-06,  5.86973438e-05,\n",
       "         -4.11780820e-05,  1.55459129e-04, -8.08899931e-05,\n",
       "         -1.44800128e-04, -2.11499006e-04, -1.69967770e-05,\n",
       "          5.73370999e-05, -6.37426565e-05,  1.70984917e-04,\n",
       "          3.44938417e-05],\n",
       "        [-1.04985840e-04,  1.24562721e-04,  2.39274916e-04,\n",
       "         -1.79055278e-04, -6.47592469e-06,  5.24256466e-05,\n",
       "         -3.67818575e-05,  1.38853633e-04, -7.22832483e-05,\n",
       "         -1.29342341e-04, -1.88882623e-04, -1.51845225e-05,\n",
       "          5.12193146e-05, -5.69467011e-05,  1.52700144e-04,\n",
       "          3.08118979e-05],\n",
       "        [-1.15178998e-04,  1.36433562e-04,  2.62053421e-04,\n",
       "         -1.96169131e-04, -7.09392634e-06,  5.74264777e-05,\n",
       "         -4.02962251e-05,  1.52110879e-04, -7.91803905e-05,\n",
       "         -1.41658005e-04, -2.06978686e-04, -1.66328809e-05,\n",
       "          5.61022971e-05, -6.23833257e-05,  1.67339967e-04,\n",
       "          3.37515376e-05],\n",
       "        [-8.86908820e-05,  1.05374376e-04,  2.02366820e-04,\n",
       "         -1.51425920e-04, -5.47775562e-06,  4.43338140e-05,\n",
       "         -3.11117183e-05,  1.17457472e-04, -6.11437063e-05,\n",
       "         -1.09479792e-04, -1.59737843e-04, -1.28399588e-05,\n",
       "          4.33237838e-05, -4.81657189e-05,  1.29129301e-04,\n",
       "          2.60587549e-05],\n",
       "        [-1.85100944e-04,  2.18487330e-04,  4.19781776e-04,\n",
       "         -3.14426783e-04, -1.13662081e-05,  9.20227831e-05,\n",
       "         -6.45538094e-05,  2.43749935e-04, -1.26791914e-04,\n",
       "         -2.26817312e-04, -3.31791758e-04, -2.66590287e-05,\n",
       "          8.98818471e-05, -9.99562690e-05,  2.68232252e-04,\n",
       "          5.40756846e-05],\n",
       "        [-1.05690109e-04,  1.25225124e-04,  2.40493915e-04,\n",
       "         -1.80058589e-04, -6.51060145e-06,  5.27028569e-05,\n",
       "         -3.69817935e-05,  1.39612515e-04, -7.26714716e-05,\n",
       "         -1.30065382e-04, -1.89919665e-04, -1.52635130e-05,\n",
       "          5.14934036e-05, -5.72656099e-05,  1.53526926e-04,\n",
       "          3.09769966e-05]], dtype=float32)>,\n",
       " <tf.Tensor: id=733, shape=(16, 6), dtype=float32, numpy=\n",
       " array([[-0.00875351,  0.0120702 ,  0.00225756, -0.00674077,  0.00837614,\n",
       "          0.00123112],\n",
       "        [-0.00747003,  0.01030041,  0.00192654, -0.00575239,  0.00714796,\n",
       "          0.00105061],\n",
       "        [-0.00736171,  0.01015106,  0.00189861, -0.00566898,  0.00704432,\n",
       "          0.00103537],\n",
       "        [-0.00743148,  0.01024725,  0.0019166 , -0.00572271,  0.00711109,\n",
       "          0.00104519],\n",
       "        [-0.00714057,  0.00984613,  0.00184157, -0.00549869,  0.00683272,\n",
       "          0.00100427],\n",
       "        [-0.00637742,  0.00879382,  0.00164476, -0.00491101,  0.00610246,\n",
       "          0.00089694],\n",
       "        [-0.00743512,  0.01025228,  0.00191754, -0.00572552,  0.00711457,\n",
       "          0.0010457 ],\n",
       "        [-0.0067061 ,  0.00924705,  0.00172952, -0.00516411,  0.00641697,\n",
       "          0.00094317],\n",
       "        [-0.00625683,  0.00862754,  0.00161366, -0.00481816,  0.00598709,\n",
       "          0.00087998],\n",
       "        [-0.00771795,  0.01064228,  0.00199048, -0.00594331,  0.00738521,\n",
       "          0.00108548],\n",
       "        [-0.00745968,  0.01028614,  0.00192388, -0.00574444,  0.00713809,\n",
       "          0.00104915],\n",
       "        [-0.00746362,  0.01029157,  0.00192489, -0.00574747,  0.00714185,\n",
       "          0.00104971],\n",
       "        [-0.0069154 ,  0.00953564,  0.0017835 , -0.0053253 ,  0.00661725,\n",
       "          0.0009726 ],\n",
       "        [-0.0065638 ,  0.00905081,  0.00169282, -0.00505454,  0.00628081,\n",
       "          0.00092315],\n",
       "        [-0.00798245,  0.01100699,  0.0020587 , -0.006147  ,  0.00763831,\n",
       "          0.00112268],\n",
       "        [-0.0067415 ,  0.00929586,  0.00173865, -0.00519138,  0.00645087,\n",
       "          0.00094815]], dtype=float32)>,\n",
       " <tf.Tensor: id=734, shape=(6, 1), dtype=float32, numpy=\n",
       " array([[-0.3825799 ],\n",
       "        [-0.39199287],\n",
       "        [-0.34260443],\n",
       "        [-0.3672076 ],\n",
       "        [-0.34602994],\n",
       "        [-0.39218238]], dtype=float32)>,\n",
       " <tf.Tensor: id=735, shape=(32,), dtype=float32, numpy=\n",
       " array([-3.30536159e-06, -1.31289180e-05,  1.49776520e-06, -1.98291455e-05,\n",
       "         1.31259849e-05, -1.86310408e-05, -6.34166281e-06, -5.71383907e-06,\n",
       "         1.89295788e-05, -1.20183167e-05,  1.31480738e-05,  1.68783481e-05,\n",
       "         1.87833157e-05, -1.12575417e-05, -2.84973139e-05,  1.19014167e-05,\n",
       "         2.30146475e-06,  3.68593064e-05,  1.28422398e-05,  1.34593229e-05,\n",
       "        -1.95411376e-05, -1.01501373e-05, -1.97515965e-06, -1.08382736e-07,\n",
       "        -1.24526650e-05, -1.07011338e-05,  2.06653658e-05, -3.54276744e-05,\n",
       "        -1.40902839e-05,  1.77908787e-05, -1.80369568e-06,  9.19588729e-06],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: id=736, shape=(16,), dtype=float32, numpy=\n",
       " array([-2.6949917e-04,  3.1888403e-04,  6.1254768e-04, -4.5865643e-04,\n",
       "        -1.6583312e-05,  1.3425341e-04, -9.4194962e-05,  3.5561257e-04,\n",
       "        -1.8504616e-04, -3.3110214e-04, -4.8389423e-04, -3.8886308e-05,\n",
       "         1.3114887e-04, -1.4583574e-04,  3.9119885e-04,  7.8903511e-05],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: id=737, shape=(6,), dtype=float32, numpy=\n",
       " array([-0.01394483,  0.01922852,  0.00359641, -0.0107384 ,  0.01334363,\n",
       "         0.00196124], dtype=float32)>,\n",
       " <tf.Tensor: id=738, shape=(1,), dtype=float32, numpy=array([-0.7669853], dtype=float32)>,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_vars = inv.trainable_variables\n",
    "gradients = g.gradient(loss, trainable_vars)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.apply_gradients(zip(gradients, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x13374ada408>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(64, 32) dtype=float32, numpy=\n",
       " array([[ 0.1499512 ,  0.03687894,  0.04996171, ...,  0.04847898,\n",
       "          0.06829581,  0.04833071],\n",
       "        [-0.0399543 ,  0.00394524,  0.02390912, ...,  0.01155864,\n",
       "         -0.03722502, -0.03666129],\n",
       "        [-0.06393464,  0.06313321, -0.02757789, ...,  0.02294632,\n",
       "          0.06605469, -0.10789549],\n",
       "        ...,\n",
       "        [-0.05742737,  0.07109744, -0.00678881, ...,  0.03579374,\n",
       "         -0.04743608, -0.05193434],\n",
       "        [-0.00542439,  0.01923782,  0.01418852, ...,  0.0790406 ,\n",
       "          0.03077881, -0.00616618],\n",
       "        [ 0.03691861, -0.0527195 , -0.01191864, ...,  0.03356226,\n",
       "          0.07611102, -0.06887035]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(32, 16) dtype=float32, numpy=\n",
       " array([[-4.18962725e-02, -2.17476636e-02, -1.11166285e-02,\n",
       "         -4.29358110e-02,  7.19985366e-02, -7.79246092e-02,\n",
       "          9.76048131e-03,  9.30439681e-03, -3.90602984e-02,\n",
       "          4.03320305e-02,  6.34792224e-02,  1.04408771e-01,\n",
       "         -2.74864007e-02,  1.42891869e-01,  5.06969690e-02,\n",
       "         -2.65327934e-02],\n",
       "        [-3.39180157e-02,  3.75476442e-02, -2.83506420e-02,\n",
       "         -7.19871074e-02,  5.67602292e-02, -5.55679761e-02,\n",
       "          6.39209710e-03,  8.15116242e-03,  8.21643621e-02,\n",
       "         -1.04345784e-01,  2.04605944e-02,  6.77890405e-02,\n",
       "          1.15614580e-02,  4.79030721e-02,  3.99437398e-02,\n",
       "         -4.00260165e-02],\n",
       "        [-7.46734515e-02,  5.57001308e-02,  2.71323770e-02,\n",
       "         -7.52288625e-02,  3.59278694e-02, -3.81784663e-02,\n",
       "         -5.34766121e-03,  1.13494527e-02,  2.77731270e-02,\n",
       "          1.08180568e-01,  1.80819519e-02, -1.38990134e-02,\n",
       "          1.95599552e-02,  2.11505853e-02,  7.67878965e-02,\n",
       "         -6.27021724e-03],\n",
       "        [-5.54868067e-03,  7.66939074e-02,  3.31873596e-02,\n",
       "         -3.68561596e-05,  2.37848721e-02,  4.64091003e-02,\n",
       "          1.33262426e-02, -7.05864467e-03,  9.51965526e-02,\n",
       "         -4.87240665e-02,  3.90273668e-02, -4.49759923e-02,\n",
       "         -7.30607137e-02, -1.15177631e-02, -3.51471305e-02,\n",
       "          3.58156636e-02],\n",
       "        [ 6.48538321e-02, -1.39136296e-02,  5.84775396e-03,\n",
       "         -2.73008682e-02, -6.68130517e-02,  4.10364680e-02,\n",
       "          4.88496721e-02, -5.23500144e-04, -1.44972764e-02,\n",
       "          4.62168083e-02,  3.94904017e-02,  5.64667359e-02,\n",
       "         -1.38519481e-02, -1.29049802e-02, -1.60275213e-02,\n",
       "         -3.68223712e-02],\n",
       "        [-3.58127430e-02, -7.64599256e-03, -9.14944336e-02,\n",
       "         -5.40797710e-02, -1.15973085e-01,  2.35007517e-02,\n",
       "         -1.52288154e-02, -6.74310140e-04,  1.42256254e-02,\n",
       "         -1.30299479e-02, -1.38840619e-02,  4.07992909e-03,\n",
       "         -4.19804268e-02,  1.53324194e-02, -1.96536481e-02,\n",
       "         -2.38525532e-02],\n",
       "        [-9.85856503e-02, -3.85037530e-03, -5.02512306e-02,\n",
       "          4.88271303e-02,  5.92529625e-02, -9.55715626e-02,\n",
       "          3.08443904e-02,  4.07737568e-02,  8.50717127e-02,\n",
       "         -4.64965738e-02,  6.38534576e-02,  7.24441633e-02,\n",
       "         -4.49725166e-02, -5.46503216e-02,  2.53634788e-02,\n",
       "         -6.90543801e-02],\n",
       "        [ 2.27192119e-02,  4.29187119e-02, -6.89076073e-03,\n",
       "          1.08438348e-02, -2.57911906e-02,  9.95249599e-02,\n",
       "          3.97095904e-02,  3.21554281e-02, -8.61990601e-02,\n",
       "         -4.66360897e-02, -2.98425462e-02,  9.31350812e-02,\n",
       "         -3.49127762e-02, -6.98372535e-03,  3.14319506e-02,\n",
       "          3.41703780e-02],\n",
       "        [ 1.52555648e-02,  8.74016881e-02,  1.96232665e-02,\n",
       "         -2.94902399e-02, -3.50264274e-02,  4.84112389e-02,\n",
       "          2.34438963e-02, -2.01768540e-02, -6.41125515e-02,\n",
       "         -2.38752961e-02, -7.72873536e-02, -9.96006578e-02,\n",
       "         -1.35246664e-03,  3.18108015e-02,  6.48794249e-02,\n",
       "         -7.97286630e-03],\n",
       "        [ 1.17433583e-02, -2.55110208e-02,  3.13298479e-02,\n",
       "         -1.95056647e-02, -1.05303749e-02,  1.10446475e-01,\n",
       "          1.70350820e-02, -2.18336470e-02, -6.74393177e-02,\n",
       "          4.70739044e-03,  1.97007246e-02, -1.00639649e-03,\n",
       "         -4.71931100e-02,  6.73437268e-02, -2.29085907e-02,\n",
       "          3.87414321e-02],\n",
       "        [-4.50153574e-02, -1.02624379e-01,  3.43364961e-02,\n",
       "          4.44661863e-02, -3.06397304e-02,  3.46267968e-02,\n",
       "         -1.68941934e-02, -6.83412626e-02,  3.16680633e-02,\n",
       "         -4.23843227e-02, -1.77155435e-02, -6.31160289e-02,\n",
       "          1.70839019e-02, -3.40163484e-02,  2.49453671e-02,\n",
       "         -9.64887440e-04],\n",
       "        [-1.75912343e-02, -7.54334703e-02, -2.31912248e-02,\n",
       "         -4.16896492e-02, -1.37936696e-03, -9.82510485e-03,\n",
       "         -1.96631104e-02, -3.29982415e-02,  7.32318088e-02,\n",
       "         -1.28138205e-02,  5.09522930e-02,  1.13633750e-02,\n",
       "          5.23236692e-02, -2.56207511e-02,  3.36855836e-02,\n",
       "          4.39065136e-03],\n",
       "        [ 2.44945846e-02, -3.82857993e-02, -4.96313684e-02,\n",
       "          3.13427523e-02,  3.90600562e-02, -4.80730385e-02,\n",
       "          3.27002369e-02, -3.19825150e-02, -5.45018539e-02,\n",
       "          2.92521510e-02, -1.81593187e-02,  3.36254612e-02,\n",
       "         -1.64497942e-02,  2.44937912e-02, -1.20771952e-01,\n",
       "          4.51270677e-02],\n",
       "        [ 9.28947628e-02, -2.90512256e-02,  2.55815685e-02,\n",
       "         -7.22469240e-02, -1.87490862e-02, -8.99608526e-03,\n",
       "          3.10287811e-02,  4.73871678e-02, -1.61918893e-01,\n",
       "          7.66493380e-04, -1.15953358e-02,  6.03855029e-02,\n",
       "          3.34854051e-02,  5.40050641e-02, -5.17176986e-02,\n",
       "         -1.79979876e-02],\n",
       "        [-3.04851364e-02,  7.64829712e-03,  7.49891400e-02,\n",
       "          1.02505963e-02,  1.10547040e-02,  2.25325637e-02,\n",
       "          6.01824000e-02, -5.50040379e-02,  2.26714741e-02,\n",
       "          4.86957543e-02, -6.98348321e-03,  7.61783496e-03,\n",
       "          1.68153960e-02, -2.31047124e-02,  4.58287522e-02,\n",
       "          7.16039538e-02],\n",
       "        [-4.72880714e-02,  6.39964864e-02, -4.50421199e-02,\n",
       "         -1.12997688e-01, -7.95299374e-03,  2.87299193e-02,\n",
       "         -5.47614098e-02,  3.41004655e-02, -1.99919119e-02,\n",
       "          5.87423965e-02, -6.27500787e-02, -7.30061810e-03,\n",
       "         -2.42283382e-02,  6.11110404e-02,  1.06975203e-02,\n",
       "         -6.71759993e-02],\n",
       "        [ 7.68879279e-02,  6.86616898e-02,  6.17669001e-02,\n",
       "         -1.29867300e-01,  2.06929967e-02, -3.86308618e-02,\n",
       "         -4.55166921e-02, -3.15375067e-02, -7.08613098e-02,\n",
       "         -3.01701631e-02, -4.37431186e-02, -3.94361094e-04,\n",
       "          6.30997121e-03,  9.96257588e-02, -9.35088657e-03,\n",
       "          1.80132315e-02],\n",
       "        [ 1.51533531e-02,  5.79356812e-02,  4.11296450e-03,\n",
       "          1.54582597e-03, -6.84221536e-02, -2.76973005e-02,\n",
       "          3.30338925e-02,  1.00883339e-02, -9.74136740e-02,\n",
       "          1.09117981e-02, -4.62872200e-02,  1.37222279e-02,\n",
       "          1.21140070e-02, -5.51466569e-02,  1.55727312e-01,\n",
       "         -1.02927461e-01],\n",
       "        [-2.64331512e-03,  4.48321644e-03, -9.04460438e-03,\n",
       "         -4.41327281e-02,  5.92707768e-02,  7.50623830e-03,\n",
       "          1.23084253e-02,  2.18772255e-02,  4.17408273e-02,\n",
       "         -7.78045356e-02,  4.35582502e-03,  1.74240023e-02,\n",
       "         -2.74634659e-02, -5.67902904e-03,  6.24991544e-02,\n",
       "          1.04649272e-03],\n",
       "        [-9.50590074e-02, -6.84185103e-02,  4.55594622e-02,\n",
       "          8.67399052e-02,  6.95978478e-02, -6.87703490e-03,\n",
       "         -6.11765385e-02, -2.50542536e-03, -3.46673690e-02,\n",
       "         -8.10688362e-02,  4.51199673e-02, -1.69608481e-02,\n",
       "          6.18403628e-02,  3.03837936e-02,  3.68126342e-03,\n",
       "         -5.27037978e-02],\n",
       "        [ 1.07072428e-01, -5.62205985e-02,  3.11718881e-02,\n",
       "         -1.61983632e-02,  2.41084993e-02,  1.03514167e-02,\n",
       "          4.42921519e-02, -3.99578176e-02, -9.56616327e-02,\n",
       "         -6.53638132e-03,  1.06664281e-03,  7.73166120e-02,\n",
       "          2.00392846e-02,  2.48834677e-02, -5.15888333e-02,\n",
       "          1.51965562e-02],\n",
       "        [-8.95624608e-02,  5.97297847e-02, -3.22760679e-02,\n",
       "         -3.08558755e-02, -3.27792987e-02,  8.07649940e-02,\n",
       "          5.42464554e-02, -2.50957794e-02,  1.97557732e-03,\n",
       "          5.64321280e-02, -3.54399756e-02, -2.22458728e-02,\n",
       "         -7.18847513e-02,  4.41803634e-02, -1.36735544e-01,\n",
       "          6.89656567e-03],\n",
       "        [ 2.75677964e-02, -1.58898160e-02,  9.41732675e-02,\n",
       "         -1.19692549e-01,  5.93167916e-02, -7.81253725e-02,\n",
       "          5.32286577e-02,  3.86149287e-02, -9.61242914e-02,\n",
       "         -2.28808057e-02, -1.36801312e-02,  6.93873167e-02,\n",
       "         -5.50212562e-02,  2.69261356e-02,  9.77909267e-02,\n",
       "         -8.81641731e-02],\n",
       "        [ 5.31499535e-02,  4.11978960e-02,  2.87584122e-03,\n",
       "          1.09643331e-02,  7.84392580e-02,  2.15094313e-02,\n",
       "          7.66074657e-02,  2.56808549e-02, -4.99256104e-02,\n",
       "          7.04570021e-03,  1.05944760e-01, -4.03367057e-02,\n",
       "         -1.05251828e-02,  7.65237585e-02, -6.64961152e-03,\n",
       "         -5.83085902e-02],\n",
       "        [ 4.32023630e-02, -1.16103832e-02,  1.72479376e-02,\n",
       "         -1.52664930e-02,  2.67504565e-02,  7.83948377e-02,\n",
       "          1.75288916e-02,  6.83182403e-02, -5.90463839e-02,\n",
       "          5.51204663e-03, -2.07284465e-02, -6.13067299e-02,\n",
       "         -3.18286493e-02, -5.80694042e-02, -4.09809835e-02,\n",
       "          5.10971341e-03],\n",
       "        [-7.83369765e-02,  4.51669842e-02, -2.29844190e-02,\n",
       "         -1.52379032e-02,  1.08099483e-01,  1.66869164e-02,\n",
       "         -2.69592665e-02,  4.76973969e-03, -3.70918959e-02,\n",
       "         -1.86437815e-02, -5.34148701e-02,  3.82958399e-03,\n",
       "         -3.49277668e-02,  9.45533216e-02, -2.68431976e-02,\n",
       "         -1.13329943e-02],\n",
       "        [-3.34257558e-02,  3.80871557e-02,  3.23976297e-03,\n",
       "          3.17638852e-02,  3.55687886e-02,  3.17749977e-02,\n",
       "         -8.40404332e-02,  4.14740629e-02,  1.82223450e-02,\n",
       "          2.23395843e-02,  3.89843136e-02, -1.24687487e-02,\n",
       "          2.07780674e-02, -8.06468911e-03, -5.17811589e-02,\n",
       "          6.78731874e-02],\n",
       "        [-9.15410072e-02,  7.96715263e-04, -3.73049825e-03,\n",
       "          2.46474110e-02,  8.10588375e-02, -5.39141148e-02,\n",
       "         -7.11230934e-02, -5.12686148e-02, -3.89826261e-02,\n",
       "         -2.19077766e-02,  2.69179083e-02,  4.25780751e-02,\n",
       "         -1.72935817e-02, -1.58248562e-02,  2.28979252e-02,\n",
       "          1.91279761e-02],\n",
       "        [-1.37185510e-02,  5.67698292e-02, -1.64856389e-02,\n",
       "         -1.09883249e-02,  7.08376989e-04, -4.71931659e-02,\n",
       "          7.42047355e-02,  1.12030152e-02, -7.52137825e-02,\n",
       "         -6.74358010e-02,  1.40626123e-02,  1.35833889e-01,\n",
       "          1.12837506e-02, -2.47590095e-02, -2.79545765e-02,\n",
       "          1.17286760e-02],\n",
       "        [-5.26694581e-02, -7.82676116e-02, -4.03487831e-02,\n",
       "         -4.41871211e-02,  3.57788764e-02,  8.17075148e-02,\n",
       "          2.07429715e-02, -2.68185455e-02,  3.06735095e-03,\n",
       "         -1.35501772e-01,  4.17965539e-02, -2.05513127e-02,\n",
       "         -5.56561127e-02,  6.26195669e-02, -1.69811957e-02,\n",
       "         -1.70670897e-02],\n",
       "        [ 1.05403382e-02, -3.25795710e-02,  3.75441797e-02,\n",
       "          2.41739973e-02, -8.07685554e-02,  2.24429201e-02,\n",
       "          2.14500893e-02,  1.91243365e-02, -1.01685468e-02,\n",
       "         -2.77471431e-02, -1.82640739e-03,  4.91774268e-02,\n",
       "         -1.65574830e-02, -2.11520195e-02,  4.42189239e-02,\n",
       "         -6.19502701e-02],\n",
       "        [ 1.98290721e-02, -8.91484246e-02, -3.83031666e-02,\n",
       "         -1.85305364e-02, -8.45818520e-02,  6.69758171e-02,\n",
       "          5.86091802e-02,  4.31877300e-02, -7.66165601e-03,\n",
       "          1.16149588e-02,  2.98424885e-02, -6.98389411e-02,\n",
       "         -7.15005957e-03,  3.53088342e-02, -2.94826739e-03,\n",
       "         -5.89374127e-03]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(16, 6) dtype=float32, numpy=\n",
       " array([[-0.00499602,  0.00686842,  0.06706672, -0.07664396, -0.00116272,\n",
       "         -0.01048912],\n",
       "        [-0.05762579,  0.04869274,  0.00417449, -0.03409972, -0.00191126,\n",
       "         -0.01435096],\n",
       "        [ 0.00403851, -0.02759893, -0.01027797, -0.01912407, -0.04838195,\n",
       "         -0.03160927],\n",
       "        [ 0.0514156 ,  0.00340815, -0.03210875, -0.04909461, -0.06926372,\n",
       "          0.00386718],\n",
       "        [-0.00673659,  0.03227825, -0.05494514,  0.00417319,  0.00243586,\n",
       "         -0.08500376],\n",
       "        [-0.00243043, -0.02996631,  0.03594981, -0.01766884,  0.12775367,\n",
       "         -0.00965498],\n",
       "        [-0.04370439,  0.08639147, -0.00724827, -0.03569506, -0.09605103,\n",
       "          0.02896857],\n",
       "        [-0.01217073, -0.08342654, -0.03394025,  0.01672865,  0.07352865,\n",
       "          0.00180186],\n",
       "        [ 0.0042172 , -0.1135236 ,  0.04586929, -0.03733885,  0.07136558,\n",
       "          0.06262695],\n",
       "        [-0.01589997, -0.00388258,  0.03101846, -0.02693816, -0.00317192,\n",
       "          0.04009288],\n",
       "        [-0.15013322,  0.04756708,  0.04289625, -0.03695327,  0.10464455,\n",
       "          0.01321251],\n",
       "        [-0.07360401,  0.0105108 ,  0.10622992, -0.05836563,  0.06444436,\n",
       "          0.05582169],\n",
       "        [ 0.00490751, -0.02816158,  0.03117929, -0.0141122 ,  0.050163  ,\n",
       "          0.07780003],\n",
       "        [-0.04568065, -0.08491646, -0.02947838,  0.05675961,  0.02270148,\n",
       "          0.04604527],\n",
       "        [-0.04489875,  0.04967544,  0.04565464,  0.02573151,  0.00740632,\n",
       "          0.02233947],\n",
       "        [-0.03062902, -0.0071132 ,  0.06511847, -0.08219524,  0.01472952,\n",
       "         -0.05632593]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(6, 1) dtype=float32, numpy=\n",
       " array([[-0.078389  ],\n",
       "        [-0.00157727],\n",
       "        [ 0.02409558],\n",
       "        [ 0.07119565],\n",
       "        [ 0.04905834],\n",
       "        [-0.04617454]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       " array([ 0.00196065, -0.01795557,  0.07056541, -0.06749775,  0.01769819,\n",
       "        -0.01520155,  0.02295909, -0.01651165, -0.05605973,  0.06012227,\n",
       "        -0.03939106,  0.00564029,  0.046341  ,  0.04020802,  0.04671104,\n",
       "         0.06479736, -0.02710209, -0.04137483,  0.08016345,  0.00265553,\n",
       "        -0.03467564, -0.07921046, -0.01367479, -0.05443364, -0.04891194,\n",
       "         0.02960777, -0.04746705, -0.08881862, -0.01104072,  0.11341009,\n",
       "         0.03153972, -0.03658564], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=\n",
       " array([-0.00049283,  0.01348833,  0.03336601, -0.00514103, -0.03363439,\n",
       "         0.04176757, -0.04177608,  0.06458264, -0.02644984,  0.01870081,\n",
       "        -0.0614989 ,  0.09385267,  0.04345888, -0.02619233, -0.04134186,\n",
       "        -0.00204307], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(6,) dtype=float32, numpy=\n",
       " array([-0.00528374, -0.06019347,  0.03749174,  0.00860549,  0.04916666,\n",
       "        -0.02175013], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.01851786], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.05711526], dtype=float32)>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "source": [
    "for step, ((x0, y0), (x1, y1)) in enumerate(zip(dataDict[0]['batch'], dataDict[1]['batch']), 1):\n",
    "    batchDataDict = {0: {'x': x0, 'y': y0}, 1: {'x': x1, 'y': y1}}\n",
    "    RunOptimizer(batchDataDict, 0.01, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(64, 32) dtype=float32, numpy=\n",
       " array([[ 0.27501473,  0.13654505,  0.15078057, ...,  0.32247686,\n",
       "          0.00610315,  0.3900001 ],\n",
       "        [ 0.00750037,  0.01874435,  0.06969524, ...,  0.2695772 ,\n",
       "         -0.05409102,  0.27882195],\n",
       "        [-0.05048328,  0.11909208, -0.04668152, ...,  0.19153905,\n",
       "         -0.0331324 ,  0.22138214],\n",
       "        ...,\n",
       "        [-0.01988893,  0.11323827,  0.04747447, ...,  0.25084564,\n",
       "         -0.08388431,  0.3066712 ],\n",
       "        [ 0.17226703,  0.10457055,  0.12667607, ...,  0.19228283,\n",
       "         -0.06529453,  0.22233121],\n",
       "        [ 0.02620078, -0.0252241 , -0.01888999, ...,  0.3003206 ,\n",
       "          0.08190741,  0.2266776 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(32, 16) dtype=float32, numpy=\n",
       " array([[ 0.21524851,  0.19695066,  0.40024558, -0.24085239,  0.27304652,\n",
       "          0.13452767, -0.17223547,  0.21960135,  0.20600691,  0.29083976,\n",
       "          0.2635001 ,  0.2927746 ,  0.20807678,  0.3334041 ,  0.25778523,\n",
       "          0.21147983],\n",
       "        [ 0.2514455 ,  0.28414798,  0.38779804, -0.29520488,  0.28747576,\n",
       "          0.18274842, -0.18739098,  0.24646963,  0.35478336,  0.17382199,\n",
       "          0.24876668,  0.28468445,  0.2738713 ,  0.26753765,  0.27842334,\n",
       "          0.22960687],\n",
       "        [ 0.09960456,  0.20851737,  0.42659205, -0.21228741,  0.17682162,\n",
       "          0.11526097, -0.15538453,  0.16244662,  0.19666973,  0.2866548 ,\n",
       "          0.16461767,  0.11965284,  0.1839874 ,  0.15611549,  0.22590087,\n",
       "          0.16218989],\n",
       "        [ 0.31920716,  0.3766878 ,  0.44287777, -0.2730417 ,  0.30661392,\n",
       "          0.3380551 , -0.21757628,  0.2810167 ,  0.42363822,  0.27552813,\n",
       "          0.31417862,  0.2158232 ,  0.23911448,  0.25339437,  0.2551227 ,\n",
       "          0.3623837 ],\n",
       "        [-0.6125953 , -0.77896345,  0.5441992 ,  0.71505564, -0.85598147,\n",
       "         -0.7032208 ,  0.79255116, -0.77378756, -0.661859  , -0.60148656,\n",
       "         -0.7140594 , -0.7373451 , -0.6696991 , -0.8051572 , -0.78083605,\n",
       "         -0.7618315 ],\n",
       "        [ 0.23348668,  0.25577548,  0.30196446, -0.29955402,  0.13321976,\n",
       "          0.27459088, -0.23419334,  0.25249046,  0.2956975 ,  0.26177946,\n",
       "          0.229155  ,  0.23649973,  0.22245829,  0.25202397,  0.23538296,\n",
       "          0.26024002],\n",
       "        [ 0.10559655,  0.14893654,  0.36982495, -0.0719435 ,  0.19779082,\n",
       "          0.04860445, -0.09431483,  0.18463811,  0.27404317,  0.1548023 ,\n",
       "          0.20111485,  0.1963004 ,  0.137093  ,  0.07233437,  0.17198066,\n",
       "          0.10455403],\n",
       "        [ 0.25800836,  0.2511993 ,  0.39523008, -0.17469451,  0.16740951,\n",
       "          0.30329186, -0.14559294,  0.23254445,  0.14297399,  0.18703917,\n",
       "          0.16207822,  0.27195746,  0.18432522,  0.1740865 ,  0.23336114,\n",
       "          0.26307094],\n",
       "        [-0.8267196 , -0.7137218 ,  0.3912025 ,  0.7446552 , -0.8312597 ,\n",
       "         -0.73845005,  0.63915896, -0.8121457 , -0.8823528 , -0.8786253 ,\n",
       "         -0.8420951 , -0.88263077, -0.8275283 , -0.7531613 , -0.7128604 ,\n",
       "         -0.82798964],\n",
       "        [ 0.16947322,  0.08526298,  0.4493443 , -0.10575593,  0.08546181,\n",
       "          0.21821912, -0.09837241,  0.08426352,  0.0663414 ,  0.15863018,\n",
       "          0.12071998,  0.0908407 ,  0.08732364,  0.1565509 ,  0.08250835,\n",
       "          0.16345996],\n",
       "        [-0.88544065, -0.90215623,  0.40431586,  0.822136  , -0.82609123,\n",
       "         -0.7512142 ,  0.5979975 , -0.8596131 , -0.78402656, -0.89489335,\n",
       "         -0.78235286, -0.8443825 , -0.806391  , -0.81797636, -0.75098145,\n",
       "         -0.820091  ],\n",
       "        [ 0.21746588,  0.12028537,  0.39084676, -0.21098524,  0.1766292 ,\n",
       "          0.17815627, -0.18496   ,  0.15308288,  0.2939979 ,  0.21763569,\n",
       "          0.22750022,  0.1761817 ,  0.26348823,  0.14129162,  0.22000529,\n",
       "          0.21692462],\n",
       "        [-0.81509835, -0.8460067 ,  0.32454285,  0.82902956, -0.7668247 ,\n",
       "         -0.8437829 ,  0.65568405, -0.83401996, -0.87391317, -0.8253747 ,\n",
       "         -0.7956933 , -0.7561316 , -0.84317803, -0.7705177 , -0.9059474 ,\n",
       "         -0.78154844],\n",
       "        [ 0.26859567,  0.10300106,  0.43866837, -0.17376018,  0.0991757 ,\n",
       "          0.12004943, -0.09869075,  0.17257297,  0.00231603,  0.1745708 ,\n",
       "          0.10967828,  0.16681583,  0.18659574,  0.16153036,  0.07705681,\n",
       "          0.13125047],\n",
       "        [-0.8804689 , -0.7828806 ,  0.5116368 ,  0.74321336, -0.77252007,\n",
       "         -0.75546974,  0.7189847 , -0.8339902 , -0.79250795, -0.8076988 ,\n",
       "         -0.7560239 , -0.76889133, -0.8125819 , -0.79756236, -0.72509533,\n",
       "         -0.7372703 ],\n",
       "        [ 0.10597163,  0.1595519 ,  0.37508565, -0.18264394,  0.07571748,\n",
       "          0.12500046, -0.15725985,  0.12617698,  0.10851582,  0.20581438,\n",
       "          0.02875732,  0.0708783 ,  0.10361774,  0.1366271 ,  0.10539655,\n",
       "          0.04788098],\n",
       "        [ 0.36713526,  0.33126482,  0.465498  , -0.3740689 ,  0.26820654,\n",
       "          0.2152367 , -0.26125777,  0.2225503 ,  0.21842976,  0.26027814,\n",
       "          0.19907834,  0.23068577,  0.28091368,  0.33355668,  0.24366929,\n",
       "          0.30367532],\n",
       "        [-0.8276532 , -0.7092299 ,  0.4087281 ,  0.71759236, -0.8303583 ,\n",
       "         -0.77890193,  0.6667141 , -0.7455748 , -0.90442413, -0.83942074,\n",
       "         -0.76998305, -0.738217  , -0.80740464, -0.8063146 , -0.58943164,\n",
       "         -0.88859457],\n",
       "        [ 0.14722219,  0.11467928,  0.40460503, -0.12689564,  0.15732934,\n",
       "          0.11800808, -0.1026775 ,  0.12818906,  0.17757894,  0.07459843,\n",
       "          0.11116614,  0.10893781,  0.10610778,  0.08609673,  0.17036666,\n",
       "          0.12710564],\n",
       "        [-0.24771494, -0.26937386,  0.4714537 ,  0.36973253, -0.14345004,\n",
       "         -0.2569839 ,  0.18745938, -0.22118558, -0.17477867, -0.21264444,\n",
       "         -0.18072385, -0.23705097, -0.09513096, -0.20449296, -0.20696375,\n",
       "         -0.2429122 ],\n",
       "        [-0.7380905 , -0.84988856,  0.41149044,  0.738694  , -0.7633188 ,\n",
       "         -0.7693432 ,  0.66344184, -0.82304156, -0.91193956, -0.86159194,\n",
       "         -0.7540767 , -0.6999501 , -0.8062496 , -0.75198716, -0.822825  ,\n",
       "         -0.7985128 ],\n",
       "        [-0.9313822 , -0.7134049 ,  0.33795083,  0.7028341 , -0.8010974 ,\n",
       "         -0.67585784,  0.6623388 , -0.787517  , -0.808251  , -0.7939902 ,\n",
       "         -0.76837385, -0.7776776 , -0.8913349 , -0.7127285 , -0.885399  ,\n",
       "         -0.7861199 ],\n",
       "        [ 0.28747487,  0.23526524,  0.4871136 , -0.3544761 ,  0.29550406,\n",
       "          0.16624577, -0.16775155,  0.28021896,  0.17968036,  0.25028515,\n",
       "          0.21926321,  0.2896206 ,  0.20640396,  0.2516885 ,  0.33872694,\n",
       "          0.18740644],\n",
       "        [ 0.35380784,  0.3349479 ,  0.40246275, -0.26764417,  0.35402244,\n",
       "          0.30810997, -0.16696209,  0.30853173,  0.25988358,  0.310195  ,\n",
       "          0.3745706 ,  0.22079252,  0.28205943,  0.3392298 ,  0.2779463 ,\n",
       "          0.2582228 ],\n",
       "        [-0.8000189 , -0.8161743 ,  0.39424074,  0.7743589 , -0.7749336 ,\n",
       "         -0.7142497 ,  0.63949805, -0.7294649 , -0.87680954, -0.8495654 ,\n",
       "         -0.7931083 , -0.8479593 , -0.8580539 , -0.8486943 , -0.82302386,\n",
       "         -0.81788135],\n",
       "        [ 0.14487368,  0.25034618,  0.3789625 , -0.20255283,  0.29811794,\n",
       "          0.21833165, -0.21669318,  0.20316999,  0.188826  ,  0.20973171,\n",
       "          0.14066634,  0.1821777 ,  0.18060952,  0.2760171 ,  0.17317453,\n",
       "          0.21307653],\n",
       "        [ 0.26415092,  0.30499828,  0.412054  , -0.21114026,  0.2848297 ,\n",
       "          0.29103306, -0.29630062,  0.29767698,  0.30928022,  0.3126752 ,\n",
       "          0.2826429 ,  0.2206096 ,  0.2979889 ,  0.22721909,  0.20634235,\n",
       "          0.3558329 ],\n",
       "        [ 0.26385784,  0.36315382,  0.38805288, -0.3194441 ,  0.42566022,\n",
       "          0.29167205, -0.3475426 ,  0.29715377,  0.3379019 ,  0.33773145,\n",
       "          0.3571993 ,  0.36670032,  0.33521912,  0.31376198,  0.37063655,\n",
       "          0.4045202 ],\n",
       "        [-0.02572106, -0.01092963,  0.4076061 ,  0.12883253, -0.0833379 ,\n",
       "         -0.15191473,  0.17915316, -0.073999  , -0.07985899, -0.06808136,\n",
       "         -0.08019768,  0.04120447, -0.01349908, -0.13241869, -0.10579322,\n",
       "         -0.03941703],\n",
       "        [-0.11629694, -0.18200299,  0.38420314,  0.10597976, -0.07899337,\n",
       "         -0.0299808 ,  0.12455627, -0.13473432, -0.06928021, -0.18506663,\n",
       "         -0.0561307 , -0.12957382, -0.1254506 , -0.05441954, -0.11803579,\n",
       "         -0.11497293],\n",
       "        [-0.83372474, -0.81001407,  0.45068258,  0.75258213, -0.8525773 ,\n",
       "         -0.7389785 ,  0.6615082 , -0.74651897, -0.81922036, -0.878252  ,\n",
       "         -0.7371709 , -0.71464074, -0.83774513, -0.78352964, -0.71201026,\n",
       "         -0.85795575],\n",
       "        [-0.07672255, -0.23037295,  0.38605204,  0.20448127, -0.24032202,\n",
       "         -0.12499354,  0.24782656, -0.11854549, -0.08954604, -0.06783248,\n",
       "         -0.14125367, -0.23470093, -0.10915143, -0.14717777, -0.15577719,\n",
       "         -0.13530393]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(16, 6) dtype=float32, numpy=\n",
       " array([[-0.51230776,  0.5227706 ,  0.556114  ,  0.44061854,  0.47699964,\n",
       "         -0.5707562 ],\n",
       "        [-0.5907938 ,  0.6898066 ,  0.5753454 ,  0.53847176,  0.540623  ,\n",
       "         -0.56402624],\n",
       "        [ 0.65061915, -0.71507126, -0.748559  , -0.6606633 , -0.7576497 ,\n",
       "          0.61269337],\n",
       "        [ 0.7982344 , -0.9411844 , -0.88067615, -0.86279917, -0.8808819 ,\n",
       "          0.6238808 ],\n",
       "        [-0.55351704,  0.6816121 ,  0.53573567,  0.58469653,  0.5649711 ,\n",
       "         -0.6358097 ],\n",
       "        [-0.44254467,  0.53333014,  0.45488158,  0.44570062,  0.52843   ,\n",
       "         -0.5374107 ],\n",
       "        [ 0.6388275 , -0.7898096 , -0.8148298 , -0.7784622 , -0.86401933,\n",
       "          0.69216555],\n",
       "        [-0.54151946,  0.54857   ,  0.52124965,  0.5783056 ,  0.60230035,\n",
       "         -0.54701424],\n",
       "        [-0.6052527 ,  0.54405403,  0.7319199 ,  0.6289479 ,  0.7265411 ,\n",
       "         -0.48264152],\n",
       "        [-0.5642268 ,  0.57671946,  0.6016027 ,  0.5604287 ,  0.5443803 ,\n",
       "         -0.51557326],\n",
       "        [-0.6903893 ,  0.68383515,  0.61437726,  0.5341573 ,  0.6512902 ,\n",
       "         -0.5316644 ],\n",
       "        [-0.5675949 ,  0.6340095 ,  0.6468326 ,  0.48083428,  0.5770701 ,\n",
       "         -0.47280908],\n",
       "        [-0.55897444,  0.5965949 ,  0.65235585,  0.61051947,  0.64059913,\n",
       "         -0.46628153],\n",
       "        [-0.55660605,  0.54685605,  0.5249296 ,  0.6047739 ,  0.54888827,\n",
       "         -0.49112958],\n",
       "        [-0.5700903 ,  0.68501896,  0.6133594 ,  0.592263  ,  0.54826075,\n",
       "         -0.51745266],\n",
       "        [-0.5939021 ,  0.64109427,  0.6644852 ,  0.52808523,  0.5843329 ,\n",
       "         -0.6136886 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(6, 1) dtype=float32, numpy=\n",
       " array([[-0.7769003 ],\n",
       "        [ 0.61436045],\n",
       "        [ 0.61068666],\n",
       "        [ 0.6661628 ],\n",
       "        [ 0.6415756 ],\n",
       "        [-0.6877047 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.82542986, -0.86028856, -0.7469456 , -0.94114107,  0.8605027 ,\n",
       "        -0.89225256, -0.7575035 , -0.85207325,  0.8192552 , -0.6611559 ,\n",
       "         0.84221977, -0.8207805 ,  0.9322358 , -0.7397025 ,  0.8551388 ,\n",
       "        -0.6670403 , -0.9004093 ,  0.7608813 , -0.66583294,  0.25229585,\n",
       "         0.80795836,  0.7914316 , -0.8826445 , -0.91601723,  0.83676594,\n",
       "        -0.8223366 , -0.902264  , -0.982327  , -0.04646725, -0.03591273,\n",
       "         0.84869874,  0.14539853], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=\n",
       " array([-0.7572609 , -0.63917935,  0.4058395 ,  0.6399476 , -0.68996   ,\n",
       "        -0.58559763,  0.5315111 , -0.57723993, -0.70787793, -0.7204074 ,\n",
       "        -0.67273796, -0.5483673 , -0.65351725, -0.6720402 , -0.66897744,\n",
       "        -0.65821815], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(6,) dtype=float32, numpy=\n",
       " array([ 0.63596416, -0.8561284 , -0.6834899 , -0.6503318 , -0.6344393 ,\n",
       "         0.5630456 ], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.32874665], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.05711526], dtype=float32)>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
