{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import ot\n",
    "import numpy as np\n",
    "from sinkhorn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvarianceTestGraph(Model, layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(InvarianceTestGraph, self).__init__()\n",
    "        \n",
    "        self.weight = {'weight1': self.add_weight(shape=(64, 32), initializer='random_normal', trainable=True), \n",
    "                        'weight2': self.add_weight(shape=(32, 16), initializer='random_normal', trainable=True), \n",
    "                        'weight3': self.add_weight(shape=(16, 6), initializer='random_normal', trainable=True),\n",
    "                        'weight_final': self.add_weight(shape = (6,2), initializer = 'random_normal', trainable = True)}\n",
    "        \n",
    "        self.bias = {'bias1': self.add_weight(shape=(32, ), initializer='random_normal', trainable=True), \n",
    "                        'bias2': self.add_weight(shape=(16, ), initializer='random_normal', trainable=True), \n",
    "                        'bias3': self.add_weight(shape=(6, ), initializer='random_normal', trainable=True),\n",
    "                        'bias_final0': self.add_weight(shape = (2,), initializer = 'random_normal', trainable = True), \n",
    "                        'bias_final1': self.add_weight(shape = (2,), initializer = 'random_normal', trainable = True)}\n",
    "        \n",
    "    def invariantMap(self, x):\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weight['weight1']), self.bias['bias1']))\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(out, self.weight['weight2']), self.bias['bias2']))\n",
    "        out = tf.nn.sigmoid(tf.add(tf.matmul(out, self.weight['weight3']), self.bias['bias3']))\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, x, env = 0):\n",
    "        out = self.invariantMap(x)\n",
    "        if env == 0:\n",
    "            out = tf.add(tf.matmul(out, self.weight['weight_final']), self.bias['bias_final0'])\n",
    "        else:\n",
    "            out = tf.add(tf.matmul(out, self.weight['weight_final']), self.bias['bias_final1'])\n",
    "        return out\n",
    "    \n",
    "inv = InvarianceTestGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = np.random.binomial(1, 0.5, (1200,))\n",
    "y1 = np.random.binomial(1, 0.8, (1500,))\n",
    "f = lambda y: np.random.normal(1, 1, (64,)) if y else np.random.normal(0, 1, (64,))\n",
    "x0 = [f(y) for y in y0]\n",
    "x1 = [f(y) for y in y1]\n",
    "y0 = tf.one_hot(y0, 2)\n",
    "y1 = tf.one_hot(y1, 2)\n",
    "x0 = tf.cast(x0, dtype=tf.float32)\n",
    "x1 = tf.cast(x1, dtype = tf.float32)\n",
    "batch0 = tf.data.Dataset.from_tensor_slices((x0, y0))\n",
    "batch1 = tf.data.Dataset.from_tensor_slices((x1, y1))\n",
    "batch0 = batch0.repeat().shuffle(5000).batch(200).prefetch(1)\n",
    "batch1 = batch1.repeat().shuffle(5000).batch(200).prefetch(1)\n",
    "\n",
    "\n",
    "learningRate = 0.01\n",
    "optimizer = tf.optimizers.Adam(learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, ((bx0, by0), (bx1, by1)) in enumerate(zip(batch0.take(120), batch1.take(150)), 1):\n",
    "    with tf.GradientTape() as g:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(by0, inv(bx0, 0))\n",
    "        loss = loss + tf.nn.softmax_cross_entropy_with_logits(by1, inv(bx1, 1))\n",
    "        loss = loss + sinkhorn_dist(bx0, bx1, 0.1, 5)\n",
    "        \n",
    "    trainable_variables = inv.trainable_variables\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0, 1, (100,64))\n",
    "y = np.random.normal(0, 1, (100,64))\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "y = tf.cast(y, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WDist(x, y, reg):\n",
    "    \"\"\"\n",
    "    :param x: (na, 2)\n",
    "    :param y: (nb, 2)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nx = x.shape[0]\n",
    "    ny = y.shape[0]\n",
    "    histX = np.ones((nx,))/nx\n",
    "    histX = tf.cast(histX, dtype = tf.float32)\n",
    "    histY = np.ones((ny,))/ny\n",
    "    histY = tf.cast(histY, dtype = tf.float32)\n",
    "    mmp1 = tf.tile(tf.expand_dims(x, axis=1), [1, y.shape[0], 1])  # (na, nb, 2)\n",
    "    mmp2 = tf.tile(tf.expand_dims(y, axis=0), [x.shape[0], 1, 1])  # (na, nb, 2)\n",
    "\n",
    "    mm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(mmp1, mmp2)), axis=2))  # (na, nb)\n",
    "    mm = tf.cast(mm, dtype = tf.float32)\n",
    "    T = ot.sinkhorn(histX, histY, mm, reg)\n",
    "    \n",
    "    \n",
    "    return np.sum(T*mm.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    x_new, y_new = inv.invariantMap(x), inv.invariantMap(y)\n",
    "    M = dist(x_new, y_new)\n",
    "    a = tf.cast(np.ones((x_new.shape[0],))/x_new.shape[0], dtype = tf.float32)\n",
    "    b = tf.cast(np.ones((y_new.shape[0],))/y_new.shape[0], dtype = tf.float32)\n",
    "    loss = sinkhorn(a, b, M, 0.1, 5)\n",
    "    \n",
    "trainable_variables = inv.trainable_variables\n",
    "gradients = g.gradient(loss, trainable_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=40174, shape=(64, 32), dtype=float32, numpy=\n",
       " array([[-1.1028768 ,  0.2919299 ,  0.37407345, ...,  0.416089  ,\n",
       "         -1.0677972 , -1.068077  ],\n",
       "        [-0.15632856, -0.03562798,  0.027945  , ..., -0.05432164,\n",
       "         -0.01674667,  0.16921844],\n",
       "        [ 2.8320374 , -0.66990876, -0.7832186 , ..., -0.89114267,\n",
       "          2.2387261 ,  2.3875136 ],\n",
       "        ...,\n",
       "        [-0.63977957,  0.08149122,  0.12310924, ...,  0.15920326,\n",
       "         -0.497426  , -0.30283564],\n",
       "        [ 0.63410676, -0.21728165, -0.20855008, ..., -0.27412713,\n",
       "          0.6971822 ,  0.66742235],\n",
       "        [ 1.0892975 , -0.23141158, -0.26879767, ..., -0.3467461 ,\n",
       "          1.0523837 ,  0.98998976]], dtype=float32)>,\n",
       " <tf.Tensor: id=40175, shape=(32, 16), dtype=float32, numpy=\n",
       " array([[ 1.145144  , -1.1650627 ,  0.9422933 ,  1.064434  , -1.4959941 ,\n",
       "         -2.0559068 ,  1.1060169 ,  0.9993057 , -2.2822943 ,  1.1701638 ,\n",
       "          1.0945299 ,  1.1645286 ,  1.1156363 ,  1.0858866 ,  1.1511474 ,\n",
       "         -1.6776923 ],\n",
       "        [-0.18838577,  0.16484202, -0.13120717, -0.13738348,  0.21181446,\n",
       "          0.14099784, -0.16565076, -0.17440917,  0.16235366, -0.21748954,\n",
       "         -0.20209017, -0.21936391, -0.1833816 , -0.1515226 , -0.19552846,\n",
       "          0.17203963],\n",
       "        [-0.21733928,  0.19098711, -0.1540436 , -0.16722356,  0.2512616 ,\n",
       "          0.19268584, -0.19338915, -0.19753051,  0.21477973, -0.24609382,\n",
       "         -0.22866361, -0.24853022, -0.20982665, -0.17852755, -0.22127892,\n",
       "          0.20973359],\n",
       "        [ 1.121482  , -1.1394573 ,  0.9220149 ,  1.0349485 , -1.4580034 ,\n",
       "         -2.0023055 ,  1.0823815 ,  0.9798442 , -2.2280252 ,  1.1425279 ,\n",
       "          1.0681592 ,  1.1385063 ,  1.0913479 ,  1.0592471 ,  1.124814  ,\n",
       "         -1.6379983 ],\n",
       "        [-0.23053786,  0.21284316, -0.16466838, -0.17652507,  0.26268628,\n",
       "          0.20900527, -0.20653345, -0.20816933,  0.23483875, -0.2592268 ,\n",
       "         -0.24282724, -0.2598083 , -0.2217676 , -0.18797077, -0.23541276,\n",
       "          0.22986181],\n",
       "        [ 0.7304232 , -0.79181266,  0.62495726,  0.6937794 , -0.94984734,\n",
       "         -1.4001119 ,  0.7061172 ,  0.6227921 , -1.5306967 ,  0.7011262 ,\n",
       "          0.67531526,  0.69479316,  0.68824714,  0.68732893,  0.706462  ,\n",
       "         -1.1224647 ],\n",
       "        [-0.22477657,  0.20538011, -0.16053131, -0.17309693,  0.2612327 ,\n",
       "          0.21653444, -0.20302069, -0.20620145,  0.2555447 , -0.25830656,\n",
       "         -0.2385964 , -0.25966203, -0.22151509, -0.18550406, -0.23642041,\n",
       "          0.23389271],\n",
       "        [-0.17061728,  0.15162735, -0.11416773, -0.12002972,  0.1825805 ,\n",
       "          0.10436954, -0.14796898, -0.15484303,  0.13168287, -0.19889967,\n",
       "         -0.18358967, -0.20056126, -0.16402918, -0.12841038, -0.17781805,\n",
       "          0.14564027],\n",
       "        [-0.2736976 ,  0.2578005 , -0.19870865, -0.21661273,  0.31469572,\n",
       "          0.28636277, -0.25011754, -0.24715061,  0.32664734, -0.30157584,\n",
       "         -0.28288525, -0.30437392, -0.26339388, -0.22880135, -0.2813477 ,\n",
       "          0.2923447 ],\n",
       "        [-0.1663138 ,  0.142758  , -0.11154894, -0.12403841,  0.1901352 ,\n",
       "          0.11197138, -0.14206743, -0.1508374 ,  0.12340847, -0.19839661,\n",
       "         -0.18345362, -0.19793737, -0.16121063, -0.13558458, -0.1754675 ,\n",
       "          0.14442013],\n",
       "        [ 1.2708845 , -1.298101  ,  1.0462656 ,  1.171737  , -1.6492083 ,\n",
       "         -2.2474413 ,  1.2266438 ,  1.1088583 , -2.4944918 ,  1.2931757 ,\n",
       "          1.2122097 ,  1.2869011 ,  1.235107  ,  1.1958207 ,  1.2683384 ,\n",
       "         -1.846674  ],\n",
       "        [-0.17081943,  0.14227602, -0.11325744, -0.12583494,  0.19218457,\n",
       "          0.12596053, -0.1507813 , -0.15700261,  0.1534439 , -0.2015194 ,\n",
       "         -0.18419755, -0.20402032, -0.16749424, -0.1385727 , -0.18221287,\n",
       "          0.15478514],\n",
       "        [ 0.5515035 , -0.61255586,  0.48132482,  0.5274422 , -0.71743596,\n",
       "         -1.0766398 ,  0.53465843,  0.4692082 , -1.1667258 ,  0.517818  ,\n",
       "          0.50504744,  0.5126523 ,  0.5153423 ,  0.5192096 ,  0.5242089 ,\n",
       "         -0.8604268 ],\n",
       "        [-0.2221383 ,  0.20173915, -0.1579494 , -0.17312151,  0.2588589 ,\n",
       "          0.20824295, -0.19952512, -0.20191331,  0.23998864, -0.25427872,\n",
       "         -0.23750797, -0.25491118, -0.21842359, -0.18465216, -0.23210815,\n",
       "          0.22800192],\n",
       "        [ 0.73630536, -0.7961173 ,  0.62995154,  0.7008889 , -0.96005905,\n",
       "         -1.4182332 ,  0.7130136 ,  0.62835723, -1.5517598 ,  0.7084394 ,\n",
       "          0.68069744,  0.7020847 ,  0.6956452 ,  0.6953206 ,  0.713814  ,\n",
       "         -1.1342663 ],\n",
       "        [-0.20617244,  0.19191328, -0.14432918, -0.15728004,  0.2303856 ,\n",
       "          0.17168427, -0.18513454, -0.18802942,  0.2019124 , -0.23524646,\n",
       "         -0.22194396, -0.23734038, -0.2002281 , -0.16582064, -0.21592665,\n",
       "          0.20066994],\n",
       "        [-0.18370494,  0.160888  , -0.12671079, -0.13533504,  0.20838895,\n",
       "          0.14412099, -0.16356379, -0.16918442,  0.17286295, -0.21526398,\n",
       "         -0.19885065, -0.21663745, -0.18075295, -0.14705554, -0.19387598,\n",
       "          0.17167231],\n",
       "        [-0.12469723,  0.10317549, -0.07760139, -0.07975881,  0.12445958,\n",
       "          0.0290204 , -0.10317302, -0.11493526,  0.03530514, -0.1507881 ,\n",
       "         -0.13807687, -0.15298954, -0.11733704, -0.0878565 , -0.12970655,\n",
       "          0.0740854 ],\n",
       "        [-0.12069506,  0.0944474 , -0.07326937, -0.07441267,  0.12223299,\n",
       "          0.02934657, -0.10018022, -0.11324441,  0.04955456, -0.14932743,\n",
       "         -0.13480166, -0.15207687, -0.1178766 , -0.0849618 , -0.13058154,\n",
       "          0.07844259],\n",
       "        [-0.12927194,  0.09831634, -0.07785207, -0.08726561,  0.13723193,\n",
       "          0.05090027, -0.10916216, -0.11957742,  0.06523953, -0.15767652,\n",
       "         -0.14294124, -0.16112635, -0.12406182, -0.09902199, -0.13928016,\n",
       "          0.08950904],\n",
       "        [-0.09322726,  0.05918913, -0.04729949, -0.0575425 ,  0.09612978,\n",
       "         -0.00413287, -0.07567887, -0.08921745,  0.01301159, -0.12410257,\n",
       "         -0.10954586, -0.12847051, -0.09294944, -0.06895184, -0.10670885,\n",
       "          0.04475981],\n",
       "        [-0.21653691,  0.19415899, -0.15507647, -0.15979275,  0.2442523 ,\n",
       "          0.17775138, -0.19004296, -0.19648583,  0.1880342 , -0.24347773,\n",
       "         -0.22467132, -0.24503422, -0.20618922, -0.17318448, -0.21416873,\n",
       "          0.19947636],\n",
       "        [-0.32092786,  0.3000372 , -0.2412444 , -0.25612965,  0.37957427,\n",
       "          0.35655293, -0.29284853, -0.28812486,  0.3857085 , -0.3480596 ,\n",
       "         -0.32690865, -0.34879163, -0.30790195, -0.2733596 , -0.31949726,\n",
       "          0.34927204],\n",
       "        [ 1.1464231 , -1.1597879 ,  0.94282925,  1.0617857 , -1.4940147 ,\n",
       "         -2.0457878 ,  1.1087011 ,  1.001685  , -2.2640908 ,  1.1659974 ,\n",
       "          1.0924709 ,  1.1625388 ,  1.1149335 ,  1.0863131 ,  1.146943  ,\n",
       "         -1.6662148 ],\n",
       "        [-0.24499966,  0.22211844, -0.1776328 , -0.19037469,  0.28730863,\n",
       "          0.24453905, -0.22188729, -0.22474244,  0.27553236, -0.2760031 ,\n",
       "         -0.25706503, -0.27840444, -0.23907417, -0.20520781, -0.25259244,\n",
       "          0.25513163],\n",
       "        [ 1.2674    , -1.3023779 ,  1.0465757 ,  1.1690705 , -1.6429073 ,\n",
       "         -2.2387953 ,  1.224613  ,  1.1069915 , -2.479476  ,  1.2882713 ,\n",
       "          1.2118534 ,  1.2823402 ,  1.2314465 ,  1.1912    ,  1.2640984 ,\n",
       "         -1.8397381 ],\n",
       "        [ 1.1106973 , -1.136692  ,  0.91614866,  1.0215085 , -1.4412528 ,\n",
       "         -1.9788117 ,  1.0708113 ,  0.970151  , -2.2049785 ,  1.1327449 ,\n",
       "          1.0577488 ,  1.1269729 ,  1.0817249 ,  1.0432626 ,  1.1113167 ,\n",
       "         -1.6218286 ],\n",
       "        [ 1.189481  , -1.2204285 ,  0.98048663,  1.0952693 , -1.54035   ,\n",
       "         -2.1071892 ,  1.1496828 ,  1.0401021 , -2.3454494 ,  1.2104328 ,\n",
       "          1.1365815 ,  1.2056206 ,  1.158081  ,  1.1171858 ,  1.1909041 ,\n",
       "         -1.7331989 ],\n",
       "        [ 1.1476419 , -1.170859  ,  0.9446206 ,  1.0659022 , -1.4997722 ,\n",
       "         -2.0634656 ,  1.110246  ,  1.0032693 , -2.2988038 ,  1.1735306 ,\n",
       "          1.0985698 ,  1.1688292 ,  1.1206267 ,  1.0876077 ,  1.1565171 ,\n",
       "         -1.6862893 ],\n",
       "        [-0.32718426,  0.31110674, -0.24505733, -0.26802212,  0.39151776,\n",
       "          0.38253167, -0.3015265 , -0.29416546,  0.42988867, -0.35885394,\n",
       "         -0.3369871 , -0.35987073, -0.3183529 , -0.28168723, -0.33374274,\n",
       "          0.37260342],\n",
       "        [ 1.215409  , -1.2449343 ,  1.0009937 ,  1.1242471 , -1.576925  ,\n",
       "         -2.156314  ,  1.1737123 ,  1.0598052 , -2.3937192 ,  1.2366678 ,\n",
       "          1.1603205 ,  1.2302507 ,  1.1806691 ,  1.1454296 ,  1.2147903 ,\n",
       "         -1.7689393 ],\n",
       "        [ 1.2352747 , -1.2619865 ,  1.0186851 ,  1.1394584 , -1.6037259 ,\n",
       "         -2.1869283 ,  1.1936467 ,  1.0789728 , -2.4206395 ,  1.2561798 ,\n",
       "          1.1786231 ,  1.2503784 ,  1.2002921 ,  1.164988  ,  1.2324147 ,\n",
       "         -1.7928197 ]], dtype=float32)>,\n",
       " <tf.Tensor: id=40176, shape=(16, 6), dtype=float32, numpy=\n",
       " array([[ -2.730579 ,  -2.5238805,   4.833786 ,  -3.3131242,  -2.9072452,\n",
       "          -2.3339841],\n",
       "        [ 12.76534  ,  19.709553 , -54.633003 ,  25.849548 ,  23.410679 ,\n",
       "          17.203693 ],\n",
       "        [ -2.8268564,  -2.643425 ,   5.1228986,  -3.4673762,  -3.046228 ,\n",
       "          -2.4409776],\n",
       "        [ -2.6953785,  -2.4777317,   4.7172422,  -3.2530906,  -2.8531609,\n",
       "          -2.2929873],\n",
       "        [ 12.668134 ,  19.58828  , -54.336456 ,  25.691936 ,  23.26902  ,\n",
       "          17.095383 ],\n",
       "        [ 12.489569 ,  19.35689  , -53.759903 ,  25.392426 ,  22.998833 ,\n",
       "          16.889362 ],\n",
       "        [ -2.7398453,  -2.5356393,   4.8618264,  -3.3280146,  -2.920772 ,\n",
       "          -2.3445292],\n",
       "        [ -2.7700381,  -2.5744805,   4.958122 ,  -3.3781316,  -2.966024 ,\n",
       "          -2.3791623],\n",
       "        [ 12.394201 ,  19.237583 , -53.467525 ,  25.237244 ,  22.859371 ,\n",
       "          16.782856 ],\n",
       "        [ -2.7146387,  -2.505342 ,   4.789614 ,  -3.288577 ,  -2.8854287,\n",
       "          -2.3173676],\n",
       "        [ -2.7863226,  -2.5960793,   5.0125012,  -3.4060326,  -2.9912481,\n",
       "          -2.3983536],\n",
       "        [ -2.7000961,  -2.4874442,   4.7463446,  -3.2653491,  -2.8645563,\n",
       "          -2.301355 ],\n",
       "        [ -2.7265854,  -2.5200477,   4.8249664,  -3.3075984,  -2.9025404,\n",
       "          -2.3305354],\n",
       "        [ -2.7055185,  -2.4906182,   4.74856  ,  -3.2695713,  -2.8680801,\n",
       "          -2.3045158],\n",
       "        [ -2.6519718,  -2.4265335,   4.5968175,  -3.1865246,  -2.7935398,\n",
       "          -2.2469838],\n",
       "        [ 12.60674  ,  19.507702 , -54.134216 ,  25.587648 ,  23.174873 ,\n",
       "          17.023731 ]], dtype=float32)>,\n",
       " <tf.Tensor: id=40177, shape=(6, 2), dtype=float32, numpy=\n",
       " array([[  342.026  ,  -342.026  ],\n",
       "        [  335.81024,  -335.81024],\n",
       "        [-1402.558  ,  1402.5579 ],\n",
       "        [  327.85156,  -327.8516 ],\n",
       "        [  330.6759 ,  -330.6759 ],\n",
       "        [  337.96503,  -337.9651 ]], dtype=float32)>,\n",
       " <tf.Tensor: id=40178, shape=(32,), dtype=float32, numpy=\n",
       " array([-5.696033  ,  1.641771  ,  2.0413213 , -6.022456  ,  1.3063967 ,\n",
       "        -0.51309025,  2.6587982 ,  1.1939311 ,  1.6224217 ,  0.47069123,\n",
       "        -6.2228    ,  2.5970044 , -0.24603795,  2.147328  , -0.7703767 ,\n",
       "         1.3964266 ,  2.1046593 ,  0.79956996,  1.0688044 ,  1.1875453 ,\n",
       "         1.02811   ,  1.5699277 ,  2.4510875 , -5.8470597 ,  3.0166938 ,\n",
       "        -6.049144  , -5.3540916 , -5.9371395 , -6.0559015 ,  2.233418  ,\n",
       "        -6.0228834 , -6.239438  ], dtype=float32)>,\n",
       " <tf.Tensor: id=40179, shape=(16,), dtype=float32, numpy=\n",
       " array([ 0.9555847 , -1.0039072 ,  0.81057096,  0.91978496, -1.2729118 ,\n",
       "        -1.8932078 ,  0.93807185,  0.82458633, -2.0988357 ,  0.94680053,\n",
       "         0.889115  ,  0.94047064,  0.9286815 ,  0.92683554,  0.9503578 ,\n",
       "        -1.4949511 ], dtype=float32)>,\n",
       " <tf.Tensor: id=40180, shape=(6,), dtype=float32, numpy=\n",
       " array([  9.946368,  17.078274, -49.542076,  22.397299,  20.378424,\n",
       "         14.773447], dtype=float32)>,\n",
       " <tf.Tensor: id=40097, shape=(2,), dtype=float32, numpy=array([-512.10956,  512.10974], dtype=float32)>,\n",
       " <tf.Tensor: id=40105, shape=(2,), dtype=float32, numpy=array([-569.6053 ,  569.60504], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = WDist(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.65166292193037"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2], [3,2], [2,4]]\n",
    "a = tf.cast(a, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15, shape=(3,), dtype=int64, numpy=array([1, 0, 1], dtype=int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(a, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
